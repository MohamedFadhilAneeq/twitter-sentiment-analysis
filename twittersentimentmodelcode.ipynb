{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "h4BBSwwdiWze",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 46658,
     "status": "ok",
     "timestamp": 1730791444343,
     "user": {
      "displayName": "Fadhil Aneeq",
      "userId": "13900735488427854544"
     },
     "user_tz": -330
    },
    "id": "h4BBSwwdiWze",
    "outputId": "a2576c4c-e4b1-4abf-e313-ae608bdcad47"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ff84403b-d849-4165-a667-d82a791c3418",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 12039,
     "status": "ok",
     "timestamp": 1730791456378,
     "user": {
      "displayName": "Fadhil Aneeq",
      "userId": "13900735488427854544"
     },
     "user_tz": -330
    },
    "id": "ff84403b-d849-4165-a667-d82a791c3418",
    "outputId": "e8c170f6-fb7b-4610-9636-6b88149a0f3b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   0           1                             2         3                4  \\\n",
      "0  0  1467810369  Mon Apr 06 22:19:45 PDT 2009  NO_QUERY  _TheSpecialOne_   \n",
      "1  0  1467810672  Mon Apr 06 22:19:49 PDT 2009  NO_QUERY    scotthamilton   \n",
      "2  0  1467810917  Mon Apr 06 22:19:53 PDT 2009  NO_QUERY         mattycus   \n",
      "3  0  1467811184  Mon Apr 06 22:19:57 PDT 2009  NO_QUERY          ElleCTF   \n",
      "4  0  1467811193  Mon Apr 06 22:19:57 PDT 2009  NO_QUERY           Karoli   \n",
      "\n",
      "                                                   5  \n",
      "0  @switchfoot http://twitpic.com/2y1zl - Awww, t...  \n",
      "1  is upset that he can't update his Facebook by ...  \n",
      "2  @Kenichan I dived many times for the ball. Man...  \n",
      "3    my whole body feels itchy and like its on fire   \n",
      "4  @nationwideclass no, it's not behaving at all....  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv(\"sentiment140.csv\", encoding='ISO-8859-1', header=None)\n",
    "# Check the data\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e2d79759-1765-4731-9517-a00241105f45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1600000 entries, 0 to 1599999\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count    Dtype \n",
      "---  ------  --------------    ----- \n",
      " 0   target  1600000 non-null  object\n",
      " 1   text    1600000 non-null  object\n",
      "dtypes: object(2)\n",
      "memory usage: 24.4+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee476f7f-1bcf-44b4-8ab6-c4d9ae2c2ac5",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 17365,
     "status": "ok",
     "timestamp": 1730791473740,
     "user": {
      "displayName": "Fadhil Aneeq",
      "userId": "13900735488427854544"
     },
     "user_tz": -330
    },
    "id": "ee476f7f-1bcf-44b4-8ab6-c4d9ae2c2ac5",
    "outputId": "4d3d5f47-2596-4c05-f46b-58102b51034f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                        cleaned_text    target\n",
      "0     a thats a bummer  you shoulda got david car...  negative\n",
      "1  is upset that he cant update his facebook by t...  negative\n",
      "2   i dived many times for the ball managed to sa...  negative\n",
      "3    my whole body feels itchy and like its on fire   negative\n",
      "4   no its not behaving at all im mad why am i he...  negative\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "def clean_tweet(text):\n",
    "    text = re.sub(r\"@\\w+\", \"\", text)               # Remove usernames\n",
    "    text = re.sub(r\"http\\S+|www\\S+|https\\S+\", \"\", text)  # Remove URLs\n",
    "    text = re.sub(r\"#(\\w+)\", \"\", text)             # Remove hashtags\n",
    "    text = re.sub(r\"[^\\w\\s]\", \"\", text)            # Remove special characters\n",
    "    text = re.sub(r\"\\d+\", \"\", text)                # Remove numbers (optional)\n",
    "    text = text.lower()                            # Convert text to lowercase\n",
    "    return text\n",
    "\n",
    "# Apply the cleaning function\n",
    "df['cleaned_text'] = df['text'].apply(clean_tweet)\n",
    "\n",
    "# Check the cleaned data\n",
    "print(df[['cleaned_text', 'target']].head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69253d6a-5f67-4979-bad6-f3242ef61c76",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 213471,
     "status": "ok",
     "timestamp": 1730791687207,
     "user": {
      "displayName": "Fadhil Aneeq",
      "userId": "13900735488427854544"
     },
     "user_tz": -330
    },
    "id": "69253d6a-5f67-4979-bad6-f3242ef61c76",
    "outputId": "fd08dbe9-2a01-42d9-cdb4-9e99f99b3bcf"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                              tokens    target\n",
      "0  [a, thats, a, bummer, you, shoulda, got, david...  negative\n",
      "1  [is, upset, that, he, cant, update, his, faceb...  negative\n",
      "2  [i, dived, many, times, for, the, ball, manage...  negative\n",
      "3  [my, whole, body, feels, itchy, and, like, its...  negative\n",
      "4  [no, its, not, behaving, at, all, im, mad, why...  negative\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "nltk.download('punkt')  # Download the tokenizer data\n",
    "\n",
    "# Tokenize each tweet\n",
    "df['tokens'] = df['cleaned_text'].apply(word_tokenize)\n",
    "\n",
    "# Check tokenized data\n",
    "print(df[['tokens', 'target']].head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d30f8edd-81b7-423d-b887-58d7ee7e04f0",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 92770,
     "status": "ok",
     "timestamp": 1730791779970,
     "user": {
      "displayName": "Fadhil Aneeq",
      "userId": "13900735488427854544"
     },
     "user_tz": -330
    },
    "id": "d30f8edd-81b7-423d-b887-58d7ee7e04f0",
    "outputId": "c12b7420-a67b-4c00-ee92-2f0e58f8732e"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /root/nltk_data...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                   lemmatized_tokens    target\n",
      "0  [a, thats, a, bummer, you, shoulda, got, david...  negative\n",
      "1  [is, upset, that, he, cant, update, his, faceb...  negative\n",
      "2  [i, dived, many, time, for, the, ball, managed...  negative\n",
      "3  [my, whole, body, feel, itchy, and, like, it, ...  negative\n",
      "4  [no, it, not, behaving, at, all, im, mad, why,...  negative\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "nltk.download('wordnet')  # Download WordNet lemmatizer data\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "# Lemmatize each word in each tweet\n",
    "df['lemmatized_tokens'] = df['tokens'].apply(lambda x: [lemmatizer.lemmatize(word) for word in x])\n",
    "\n",
    "# Check lemmatized tokens\n",
    "print(df[['lemmatized_tokens', 'target']].head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9141ee1a-0aa4-42a6-b3a4-1622b15ba7e2",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1947,
     "status": "ok",
     "timestamp": 1730791781911,
     "user": {
      "displayName": "Fadhil Aneeq",
      "userId": "13900735488427854544"
     },
     "user_tz": -330
    },
    "id": "9141ee1a-0aa4-42a6-b3a4-1622b15ba7e2",
    "outputId": "75d12cb6-4090-423a-d5cb-261389fa8289"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                      processed_text    target\n",
      "0  a thats a bummer you shoulda got david carr of...  negative\n",
      "1  is upset that he cant update his facebook by t...  negative\n",
      "2  i dived many time for the ball managed to save...  negative\n",
      "3       my whole body feel itchy and like it on fire  negative\n",
      "4  no it not behaving at all im mad why am i here...  negative\n"
     ]
    }
   ],
   "source": [
    "df['processed_text'] = df['lemmatized_tokens'].apply(lambda x: ' '.join(x))\n",
    "print(df[['processed_text', 'target']].head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "LehK4FhsRmcv",
   "metadata": {
    "id": "LehK4FhsRmcv"
   },
   "outputs": [],
   "source": [
    "# Add New Features\n",
    "df['text_length'] = df['text'].apply(len)\n",
    "df['exclamation_count'] = df['text'].apply(lambda x: x.count('!'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "571c33a5-4d32-4465-9f4f-8d07223b8464",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 96206,
     "status": "ok",
     "timestamp": 1730796009644,
     "user": {
      "displayName": "Fadhil Aneeq",
      "userId": "13900735488427854544"
     },
     "user_tz": -330
    },
    "id": "571c33a5-4d32-4465-9f4f-8d07223b8464",
    "outputId": "ca7c3f64-98e5-486a-85aa-72ec2221cdd4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF-IDF feature matrix shape: (1600000, 5000)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from scipy.sparse import hstack\n",
    "# Initialize the vectorizer with a maximum feature limit for simplicity\n",
    "tfidf_vectorizer = TfidfVectorizer(ngram_range=(1, 2), max_features=5000)  # Limiting to 5000 words for efficiency\n",
    "\n",
    "# Transform the cleaned text column into TF-IDF features\n",
    "X = tfidf_vectorizer.fit_transform(df['processed_text'])\n",
    "\n",
    "X_extra = hstack((X, df[['text_length', 'exclamation_count']].values))\n",
    "\n",
    "# Check the shape of the feature matrix\n",
    "print(\"TF-IDF feature matrix shape:\", X.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cba5fb1b-d8fd-49cd-9f49-8285df579f04",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 16,
     "status": "ok",
     "timestamp": 1730796009645,
     "user": {
      "displayName": "Fadhil Aneeq",
      "userId": "13900735488427854544"
     },
     "user_tz": -330
    },
    "id": "cba5fb1b-d8fd-49cd-9f49-8285df579f04",
    "outputId": "d05bf764-26a6-4079-c8b9-c263ff149f70"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoded labels: [0 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Initialize the label encoder\n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "# Encode target labels to numerical values\n",
    "y = label_encoder.fit_transform(df['target'])\n",
    "\n",
    "# Check the encoded labels\n",
    "print(\"Encoded labels:\", y[:5])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdaf3e5d-01fe-478f-893c-05a4df69b97e",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 849,
     "status": "ok",
     "timestamp": 1730796061301,
     "user": {
      "displayName": "Fadhil Aneeq",
      "userId": "13900735488427854544"
     },
     "user_tz": -330
    },
    "id": "cdaf3e5d-01fe-478f-893c-05a4df69b97e",
    "outputId": "102d05fa-92be-44d9-c368-d5bb255e09bd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set size: (1280000, 5000)\n",
      "Testing set size: (320000, 5000)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "print(\"Training set size:\", X_train.shape)\n",
    "print(\"Testing set size:\", X_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50ae6668-9f51-43d4-8dba-62d2884db4bb",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 14435,
     "status": "ok",
     "timestamp": 1730796077297,
     "user": {
      "displayName": "Fadhil Aneeq",
      "userId": "13900735488427854544"
     },
     "user_tz": -330
    },
    "id": "50ae6668-9f51-43d4-8dba-62d2884db4bb",
    "outputId": "2a82b16e-e2cb-40bc-b7ce-637f8a0d1fd6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Accuracy: 0.79599375\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.80      0.78      0.79    159494\n",
      "    positive       0.79      0.81      0.80    160506\n",
      "\n",
      "    accuracy                           0.80    320000\n",
      "   macro avg       0.80      0.80      0.80    320000\n",
      "weighted avg       0.80      0.80      0.80    320000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Initialize and train the Logistic Regression model\n",
    "log_reg = LogisticRegression(max_iter=1000)  # Increase max_iter if needed\n",
    "log_reg.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = log_reg.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Logistic Regression Accuracy:\", accuracy)\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred, target_names=label_encoder.classes_))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bedb789-612b-4810-a505-abd7b3723ab4",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 678,
     "status": "ok",
     "timestamp": 1730796079919,
     "user": {
      "displayName": "Fadhil Aneeq",
      "userId": "13900735488427854544"
     },
     "user_tz": -330
    },
    "id": "0bedb789-612b-4810-a505-abd7b3723ab4",
    "outputId": "847ea550-ad99-4c63-f109-eabdd1fc2ba1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tweet: @switchfoot http://twitpic.com/2y1zl - Awww, that's a bummer.  You shoulda got David Carr of Third Day to do it. ;D\n",
      "Actual: negative\n",
      "Predicted: positive\n",
      "\n",
      "Tweet: is upset that he can't update his Facebook by texting it... and might cry as a result  School today also. Blah!\n",
      "Actual: negative\n",
      "Predicted: positive\n",
      "\n",
      "Tweet: @Kenichan I dived many times for the ball. Managed to save 50%  The rest go out of bounds\n",
      "Actual: negative\n",
      "Predicted: positive\n",
      "\n",
      "Tweet: spring break in plain city... it's snowing \n",
      "Actual: positive\n",
      "Predicted: negative\n",
      "\n",
      "Tweet: @octolinz16 It it counts, idk why I did either. you never talk to me anymore \n",
      "Actual: negative\n",
      "Predicted: positive\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Find misclassified examples for logistic regression\n",
    "misclassified_idx = np.where(y_test != y_pred)[0]\n",
    "misclassified_samples = [(df['text'].iloc[i], y_test[i], y_pred[i]) for i in misclassified_idx[:5]]\n",
    "for tweet, actual, predicted in misclassified_samples:\n",
    "    print(f\"Tweet: {tweet}\\nActual: {label_encoder.classes_[actual]}\\nPredicted: {label_encoder.classes_[predicted]}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69310573-92bf-4949-9ee7-d06c1bc48529",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 424,
     "status": "ok",
     "timestamp": 1730796081658,
     "user": {
      "displayName": "Fadhil Aneeq",
      "userId": "13900735488427854544"
     },
     "user_tz": -330
    },
    "id": "69310573-92bf-4949-9ee7-d06c1bc48529",
    "outputId": "4a3d7a20-cf17-4c53-8de7-b7ab54c7b703"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['tfidf_vectorizer.pkl']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "# Save the logistic regression model\n",
    "joblib.dump(log_reg, 'logistic_regression_model.pkl')\n",
    "\n",
    "# Save the TF-IDF vectorizer\n",
    "joblib.dump(tfidf_vectorizer, 'tfidf_vectorizer.pkl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fd02dce-f3c7-4f69-abde-148e14ed1e34",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 453,
     "status": "ok",
     "timestamp": 1730796083442,
     "user": {
      "displayName": "Fadhil Aneeq",
      "userId": "13900735488427854544"
     },
     "user_tz": -330
    },
    "id": "4fd02dce-f3c7-4f69-abde-148e14ed1e34",
    "outputId": "915a81c0-ec58-4fe8-99c6-005110898e12"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Sentiment: ['positive']\n"
     ]
    }
   ],
   "source": [
    "# Load the model and vectorizer\n",
    "loaded_model = joblib.load('logistic_regression_model.pkl')\n",
    "loaded_vectorizer = joblib.load('tfidf_vectorizer.pkl')\n",
    "\n",
    "# Example of a new tweet\n",
    "new_tweet = [\"I'm so happy with this product!\"]\n",
    "\n",
    "# Preprocess and vectorize the new tweet\n",
    "new_tweet_cleaned = [clean_tweet(new_tweet[0])]  # Simplify by using the existing cleaning function\n",
    "new_tweet_vectorized = loaded_vectorizer.transform(new_tweet_cleaned)\n",
    "\n",
    "# Predict sentiment\n",
    "predicted_sentiment = loaded_model.predict(new_tweet_vectorized)\n",
    "print(\"Predicted Sentiment:\", label_encoder.inverse_transform(predicted_sentiment))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0be92e75-8d56-464d-be22-9120ce6da1eb",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1730796084738,
     "user": {
      "displayName": "Fadhil Aneeq",
      "userId": "13900735488427854544"
     },
     "user_tz": -330
    },
    "id": "0be92e75-8d56-464d-be22-9120ce6da1eb",
    "outputId": "ec34d523-4efc-4fa6-9df6-5e740dd154a0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tweet: I'm so happy with this product!\n",
      "Predicted Sentiment: positive\n",
      "\n",
      "Tweet: This is the worst experience I've ever had.\n",
      "Predicted Sentiment: negative\n",
      "\n",
      "Tweet: It's okay, nothing special.\n",
      "Predicted Sentiment: positive\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Test with a few sample tweets\n",
    "sample_tweets = [\n",
    "    \"I'm so happy with this product!\",\n",
    "    \"This is the worst experience I've ever had.\",\n",
    "    \"It's okay, nothing special.\"\n",
    "]\n",
    "\n",
    "for tweet in sample_tweets:\n",
    "    tweet_cleaned = [clean_tweet(tweet)]\n",
    "    tweet_vectorized = loaded_vectorizer.transform(tweet_cleaned)\n",
    "    sentiment = loaded_model.predict(tweet_vectorized)\n",
    "    print(f\"Tweet: {tweet}\\nPredicted Sentiment: {label_encoder.inverse_transform(sentiment)[0]}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ef0d786-309f-44dd-9ff7-b0fb7799d88f",
   "metadata": {
    "id": "2ef0d786-309f-44dd-9ff7-b0fb7799d88f"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
